{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Classified\n",
      "Data Filtered\n",
      "Original Data Classified, Filtered, and Saved to the path MI 2 Rows of Couties North of IN-OH.xlsx SCRUBBED.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n",
    "EXCEL_FILE_PATH = \"MI 2 Rows of Couties North of IN-OH.xlsx\"\n",
    "MODEL_FILE_PATH = \"logreg_classifier.pickle\"\n",
    "VECTORIZER_FILE_PATH = \"logreg_vectorizer.pickle\"\n",
    "FILTERED_FILE_PATH = f\"{EXCEL_FILE_PATH} Classified.xlsx\"\n",
    "OUTPUT_FILE_PATH = f\"{EXCEL_FILE_PATH} SCRUBBED.xlsx\"\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        return pd.read_excel(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def clean_data(df):\n",
    "    df.dropna(subset=['MAIL_ADDR', 'MAIL_CITY', 'MAIL_STATE', 'MAIL_ZIP', 'OWNER_NAME_1'], inplace=True)\n",
    "    df.drop_duplicates(subset=['MAIL_ADDR', 'MAIL_CITY', 'MAIL_STATE', 'MAIL_ZIP'], inplace=True)\n",
    "    df['Full Name'] = df['OWNER_NAME_1'].str.replace(',', '').str.replace('&', '')\n",
    "    return df\n",
    "\n",
    "def load_model_and_vectorizer(model_path, vectorizer_path):\n",
    "    try:\n",
    "        with open(model_path, \"rb\") as model_file:\n",
    "            model = pickle.load(model_file)\n",
    "        with open(vectorizer_path, \"rb\") as vec_file:\n",
    "            vectorizer = pickle.load(vec_file)\n",
    "        return model, vectorizer\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e.filename}\")\n",
    "        return None, None\n",
    "\n",
    "def predict_names(df, model, vectorizer):\n",
    "    if 'OWNER_NAME_1' in df.columns:\n",
    "        X_test = vectorizer.transform(df['OWNER_NAME_1'])\n",
    "        df['Prediction'] = model.predict(X_test)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"The 'OWNER_NAME_1' column is missing from the Excel file.\")\n",
    "        return df\n",
    "\n",
    "def save_predictions(df, file_path):\n",
    "    df.to_excel(file_path, index=False)\n",
    "\n",
    "def filter_company_names(df, human_names):\n",
    "    df = df[df['OWNER_NAME_1'].isin(human_names)]\n",
    "    return df\n",
    "\n",
    "def remove_suspected_company_names(df, keywords):\n",
    "    pattern = r'\\b(?:' + '|'.join(map(re.escape, keywords)) + r')\\b'\n",
    "    df = df[~df['OWNER_NAME_1'].str.contains(pattern, case=False, na=False)]\n",
    "    return df\n",
    "\n",
    "\n",
    "# Main process\n",
    "df = load_data(EXCEL_FILE_PATH)\n",
    "df = clean_data(df)\n",
    "\n",
    "model, vectorizer = load_model_and_vectorizer(MODEL_FILE_PATH, VECTORIZER_FILE_PATH)\n",
    "if model and vectorizer:\n",
    "    df = predict_names(df, model, vectorizer)\n",
    "    save_predictions(df[['OWNER_NAME_1', 'Prediction']], FILTERED_FILE_PATH)\n",
    "    print(\"Data Classified\")\n",
    "     \n",
    "    filtered_df = load_data(FILTERED_FILE_PATH)\n",
    "    human_names = filtered_df[filtered_df['Prediction'] == 'Human Name']['OWNER_NAME_1'].unique().tolist()\n",
    "    df = filter_company_names(df, human_names)\n",
    "    print(\"Data Filtered\")\n",
    "\n",
    "    # List of keywords indicating company names\n",
    "    company_keywords = ['OF', 'SERVICES', 'COUNTY', 'DISTRIBUTOR', 'PRODUCTS', 'COUNTRY CLUB', 'PLLC', 'PRIVATE',\n",
    "                        'COMPANY', 'INC', 'RETIREMENT', 'DEVELOPMENT', 'HOA', 'AUTHORITY', 'CONF', 'CONFERENCE',\n",
    "                        'CONSTRUCTION', 'AFFORDABLE', 'HOUSING', 'MID COAST', 'ESTATE', 'REHABILITATION', 'GARDENS',\n",
    "                        'WELLNESS', 'LLC', 'STATE', 'LAND', 'MEMBERSHIP', 'COOPERATIVE', 'CORP', 'CORPORATION',\n",
    "                        'INDEPENDENT', 'CHURCH', 'ENTERPRISES', 'ACCOUNTING', 'INVESTMENTS', 'OWNERS', 'AIRPORT',\n",
    "                        'MAINTENANCE', 'ASSOCIATION', 'REALTY', 'FOUNDATION', 'CONSULTANTS', 'ASSOCIATES',\n",
    "                        'CORPORATE', 'DISTRICT', 'LTD', 'LIMITED', 'INCORPORATED', 'PROPERTIES', 'INVESTMENT',\n",
    "                        'NORTHEAST', 'PLUMBING', 'HEATING', \"T V A\", 'New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix',\n",
    "                        'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose', 'Austin', 'Jacksonville', 'Fort Worth',\n",
    "                        'Columbus', 'San Francisco', 'Charlotte', 'Indianapolis', 'Seattle', 'Denver', 'Washington', 'Boston',\n",
    "                        'El Paso', 'Nashville', 'Detroit', 'Oklahoma City', 'Portland', 'Las Vegas', 'Memphis', 'Louisville',\n",
    "                        'Baltimore', 'Milwaukee', 'Albuquerque', 'Tucson', 'Fresno', 'Sacramento', 'Kansas City', 'Atlanta',\n",
    "                        'Miami', 'Colorado Springs', 'Raleigh', 'Omaha', 'Long Beach', 'Virginia Beach', 'Oakland', 'Minneapolis',\n",
    "                        'Tulsa', 'Arlington', 'Tampa', 'New Orleans', 'Wichita', 'Alabama', 'AL', 'Alaska', 'AK', 'Arizona', 'AZ',\n",
    "                        'Arkansas', 'AR', 'California', 'CA', 'Colorado', 'CO', 'Connecticut', 'CT', 'Delaware', 'DE', 'Florida', 'FL',\n",
    "                        'Georgia', 'GA', 'Hawaii', 'HI', 'Idaho', 'ID', 'Illinois', 'IL', 'Indiana', 'IN', 'Iowa', 'IA', 'Kansas', 'KS',\n",
    "                        'Kentucky', 'KY', 'Louisiana', 'LA', 'Maine', 'ME', 'Maryland', 'MD', 'Massachusetts', 'MA', 'Michigan', 'MI',\n",
    "                        'Minnesota', 'MN', 'Mississippi', 'MS', 'Missouri', 'MO', 'Montana', 'MT', 'Nebraska', 'NE', 'Nevada', 'NV',\n",
    "                        'New Hampshire', 'NH', 'New Jersey', 'NJ', 'New Mexico', 'NM', 'New York', 'NY', 'North Carolina', 'NC',\n",
    "                        'North Dakota', 'ND', 'Ohio', 'OH', 'Oklahoma', 'OK', 'Oregon', 'OR', 'Pennsylvania', 'PA', 'Rhode Island', 'RI',\n",
    "                        'South Carolina', 'SC', 'South Dakota', 'SD', 'Tennessee', 'TN', 'Texas', 'TX', 'Utah', 'UT', 'Vermont', 'VT',\n",
    "                        'Virginia', 'VA', 'Washington', 'WA', 'West Virginia', 'WV', 'Wisconsin', 'WI', 'Wyoming', 'WY',\n",
    "                        'Co', 'Inc', 'LLC', 'Ltd', 'Corp', 'Pty', 'PLC', 'GmbH', 'S.A.', 'S.A.S.', 'AG', 'N.V.', 'B.V.', 'K.K.', 'S.R.L.',\n",
    "                        'P.C.', 'C.A.', 'd.o.o.', 'P.L.C.', 'S.p.A.', 'A.G.', 'a.s.', 'OÃœ', 'Oy', 'ApS', 's.r.o.', 'S.A.B.', 'S.L.', 'AB',\n",
    "                        'CASS', 'ILE', 'BRANCH', 'ST', 'HCMA', 'ITC', 'TRANSMISSION', 'ENTERPRISES']\n",
    "\n",
    "    df = remove_suspected_company_names(df, company_keywords)\n",
    "    save_predictions(df, OUTPUT_FILE_PATH)\n",
    "    print(f\"Original Data Classified, Filtered, and Saved to the path {OUTPUT_FILE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
