{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy.language import Language\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('OR Crook 3-9.99.xlsx - Sheet1.csv')\n",
    "\n",
    "# Data cleaning\n",
    "df.dropna(subset=['MAIL_ADDR','MAIL_CITY','MAIL_STATE','MAIL_ZIP','OWNER_NAME_1'], inplace=True)\n",
    "df = df.drop_duplicates(['MAIL_ADDR','MAIL_CITY','MAIL_STATE','MAIL_ZIP'])\n",
    "\n",
    "# Remove commas and strip whitespace\n",
    "df['OWNER_NAME_1'] = df['OWNER_NAME_1'].str.replace(',', '').str.strip()\n",
    "\n",
    "# List of keywords indicating company names\n",
    "Suspected_Words = [\n",
    "    'OF', 'SERVICES', 'COUNTY', 'DISTRIBUTOR', 'PRODUCTS', 'COUNTRY CLUB', 'PLLC', 'PRIVATE',\n",
    "    'COMPANY', 'INC', 'RETIREMENT', 'DEVELOPMENT', 'HOA', 'AUTHORITY', 'CONF', 'CONFERENCE',\n",
    "    'CONSTRUCTION', 'AFFORDABLE', 'HOUSING', 'MID COAST', 'ESTATE', 'REHABILITATION', 'GARDENS',\n",
    "    'WELLNESS', 'LLC', 'STATE', 'LAND', 'MEMBERSHIP', 'COOPERATIVE', 'CORP', 'CORPORATION',\n",
    "    'INDEPENDENT', 'CHURCH', 'ENTERPRISES', 'ACCOUNTING', 'INVESTMENTS', 'OWNERS', 'AIRPORT',\n",
    "    'MAINTENANCE', 'ASSOCIATION', 'REALTY', 'FOUNDATION', 'CONSULTANTS', 'ASSOCIATES',\n",
    "    'CORPORATE', 'DISTRICT', 'LTD', 'LIMITED', 'INCORPORATED', 'PROPERTIES', 'INVESTMENT',\n",
    "    'NORTHEAST', 'PLUMBING', 'HEATING', 'TRUST'\n",
    "]\n",
    "\n",
    "# Pattern to detect suspected company names\n",
    "pattern = r'\\b(' + '|'.join(Suspected_Words) + r')\\b'\n",
    "\n",
    "# Filter out suspected company names\n",
    "df = df[~df['OWNER_NAME_1'].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "# Load spaCy's pre-trained model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define custom NER component\n",
    "@Language.component(\"custom_ner\")\n",
    "def custom_ner(doc):\n",
    "    new_ents = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ORG\":\n",
    "            new_ents.append(Span(doc, ent.start, ent.end, label=\"COMPANY\"))\n",
    "        else:\n",
    "            new_ents.append(ent)\n",
    "    doc.ents = new_ents\n",
    "    return doc\n",
    "\n",
    "# Add custom NER component to the pipeline\n",
    "nlp.add_pipe(\"custom_ner\", last=True)\n",
    "\n",
    "# Define a function to classify names\n",
    "def classify_name(name):\n",
    "    try:\n",
    "        doc = nlp(name)\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                return \"Human Name\"\n",
    "            elif ent.label_ == \"COMPANY\":\n",
    "                return \"Company Name\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing name '{name}': {e}\")\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Apply the classification function to the \"OWNER_NAME_1\" column\n",
    "df[\"Name Type\"] = df[\"OWNER_NAME_1\"].apply(classify_name)\n",
    "\n",
    "# Save the results to a new CSV\n",
    "df.to_csv('Removed_keywords_datasheet.csv', index=False)\n",
    "print(\"Classification complete. Results saved to 'Removed_keywords_datasheet.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The rest of this notebook is still not done and ***Can't be Used***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "# Generating synthetic data for testing\n",
    "def generate_synthetic_data(num_records=500):\n",
    "    # Lists of common human first and last names and company keywords\n",
    "    human_first_names = [\"John\", \"Jane\", \"Alex\", \"Emily\", \"Michael\", \"Sarah\", \"David\", \"Laura\", \"James\", \"Emma\"]\n",
    "    human_last_names = [\"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\", \"Rodriguez\", \"Martinez\"]\n",
    "    \n",
    "    # List of keywords indicating company names\n",
    "    company_keywords = ['OF', 'SERVICES','COUNTY','DISTRIBUTOR','PRODUCTS',' COUNTRY CLUB','PLLC','PRIVATE''COMPANY', 'INC','RETIREMENT','DEVELOPMENT','HOA','AUTHORITY','CONF','CONFERENCE','CONSTRCTN','AFFORDABLE','HSNG','MID COAST','ESTATE','REHABILITATION','GARDENS','WELLNESS'\n",
    "                    'LLC', 'STATE', 'LAND','MEMBERSHIP','COOPERATIVE' 'CORP','CORPORATION','INDEPENDENT','ARCARE','CHURCH','ENTERPRISES','ACCOUNTING','INVESTMENTS','OWNERS','AIRPORT','MAINTENANCE','MOTORCYCLE','ASSOC','EXCAVATING','EXCAVATION','PROPS','RECREATIONAL','VILLAGE','FOR','GROUND','REAL'\n",
    "                    'CO', 'REALTY', 'CONSTRUCTION', 'FOUNDATION', 'CONSULTANTS', 'ASSOCIATES', 'CORPORATE','DISTRICT','LTD','LIMITED','INCORPORATED','PROPERTIES','INVESTMENT','ASSN','TRAILS','NORTHEAST','ESTS','RIVERGATE','PLUMBING','HEATING']\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for _ in range(num_records):\n",
    "        # Randomly decide to create a human name or company name\n",
    "        if random.random() < 0.5:\n",
    "            # Create a human name\n",
    "            first_name = random.choice(human_first_names)\n",
    "            last_name = random.choice(human_last_names)\n",
    "            full_name = f\"{first_name} {last_name}\"\n",
    "            data.append({\"Full Name\": full_name, \"Name Type\": \"Human Name\"})\n",
    "        else:\n",
    "            # Create a company name\n",
    "            company_name = f\"{random.choice(human_last_names)} {random.choice(company_keywords)}\"\n",
    "            data.append({\"Full Name\": company_name, \"Name Type\": \"Company Name\"})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation:\n",
    "- High Precision for Human Names: The model is very precise in identifying human names, with few false positives.\n",
    "- High Recall for Company Names: The model correctly identifies most company names, missing only a small percentage.\n",
    "- Lower Recall for Human Names: The model is less effective at identifying all human names, as indicated by the lower recall.\n",
    "\n",
    "- ***Overall, the model performs well with a balanced F1-score of 0.92 for both classes. However, it is slightly better at classifying company names (higher recall) than human names. Further tuning, such as optimizing the decision threshold or incorporating more features, could improve performance.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ak758\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on Test Set: 98.99%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Company Name       0.99      0.99      0.99      2873\n",
      "  Human Name       0.99      0.99      0.99      3168\n",
      "\n",
      "    accuracy                           0.99      6041\n",
      "   macro avg       0.99      0.99      0.99      6041\n",
      "weighted avg       0.99      0.99      0.99      6041\n",
      "\n",
      "[[2835   38]\n",
      " [  23 3145]]\n",
      "Accuracy on Synthetic Data: 92.20%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Company Name       0.89      0.96      0.92       249\n",
      "  Human Name       0.96      0.88      0.92       251\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.92      0.92      0.92       500\n",
      "weighted avg       0.93      0.92      0.92       500\n",
      "\n",
      "[[240   9]\n",
      " [ 30 221]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Ensure necessary NLTK data files are downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Generate synthetic data for testing\n",
    "def generate_synthetic_data(num_records=500):\n",
    "    human_first_names = [\"John\", \"Jane\", \"Alex\", \"Emily\", \"Michael\", \"Sarah\", \"David\", \"Laura\", \"James\", \"Emma\"]\n",
    "    human_last_names = [\"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\", \"Rodriguez\", \"Martinez\"]\n",
    "    company_keywords = ['OF', 'SERVICES', 'COUNTY', 'DISTRIBUTOR', 'PRODUCTS', 'COUNTRY CLUB', 'PLLC', 'PRIVATE', \n",
    "                        'COMPANY', 'INC', 'RETIREMENT', 'DEVELOPMENT', 'HOA', 'AUTHORITY', 'CONF', 'CONFERENCE', \n",
    "                        'CONSTRUCTION', 'AFFORDABLE', 'HOUSING', 'MID COAST', 'ESTATE', 'REHABILITATION', 'GARDENS', \n",
    "                        'WELLNESS', 'LLC', 'STATE', 'LAND', 'MEMBERSHIP', 'COOPERATIVE', 'CORP', 'CORPORATION', \n",
    "                        'INDEPENDENT', 'CHURCH', 'ENTERPRISES', 'ACCOUNTING', 'INVESTMENTS', 'OWNERS', 'AIRPORT', \n",
    "                        'MAINTENANCE', 'ASSOCIATION', 'REALTY', 'FOUNDATION', 'CONSULTANTS', 'ASSOCIATES', \n",
    "                        'CORPORATE', 'DISTRICT', 'LTD', 'LIMITED', 'INCORPORATED', 'PROPERTIES', 'INVESTMENT', \n",
    "                        'NORTHEAST', 'PLUMBING', 'HEATING', 'TRUST']\n",
    "\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        if random.random() < 0.5:\n",
    "            first_name = random.choice(human_first_names)\n",
    "            last_name = random.choice(human_last_names)\n",
    "            full_name = f\"{first_name} {last_name}\"\n",
    "            data.append({\"Full Name\": full_name, \"Name Type\": \"Human Name\"})\n",
    "        else:\n",
    "            company_name = f\"{random.choice(human_last_names)} {random.choice(company_keywords)}\"\n",
    "            data.append({\"Full Name\": company_name, \"Name Type\": \"Company Name\"})\n",
    "    return data\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_excel(\"Training Data Scrubbing Names 2.xlsx\")\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='char')\n",
    "X = vectorizer.fit_transform(df['Full Name'])\n",
    "y = df['Name Type']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, penalty='l2', C=1.0, solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy on Test Set: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Generate and test with synthetic data\n",
    "synthetic_data = generate_synthetic_data(500)\n",
    "synthetic_X = vectorizer.transform([row['Full Name'] for row in synthetic_data])\n",
    "synthetic_y = [row['Name Type'] for row in synthetic_data]\n",
    "\n",
    "# Evaluate on synthetic data\n",
    "synthetic_pred = model.predict(synthetic_X)\n",
    "synthetic_accuracy = accuracy_score(synthetic_y, synthetic_pred)\n",
    "print(f\"Accuracy on Synthetic Data: {synthetic_accuracy * 100:.2f}%\")\n",
    "print(classification_report(synthetic_y, synthetic_pred))\n",
    "print(confusion_matrix(synthetic_y, synthetic_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applying Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ak758\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on Test Set: 98.46%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Company Name       0.99      0.98      0.98      2899\n",
      "  Human Name       0.98      0.99      0.99      3142\n",
      "\n",
      "    accuracy                           0.98      6041\n",
      "   macro avg       0.98      0.98      0.98      6041\n",
      "weighted avg       0.98      0.98      0.98      6041\n",
      "\n",
      "[[2834   65]\n",
      " [  28 3114]]\n",
      "Accuracy on Synthetic Data: 93.70%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Company Name       0.95      0.92      0.94       989\n",
      "  Human Name       0.92      0.95      0.94      1011\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.94      0.94      0.94      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n",
      "[[909  80]\n",
      " [ 46 965]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "\n",
    "# Ensure necessary NLTK data files are downloaded\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Generate synthetic data for testing\n",
    "def generate_synthetic_data(num_records=1000):\n",
    "    human_first_names = [\"John\", \"Jane\", \"Alex\", \"Emily\", \"Michael\", \"Sarah\", \"David\", \"Laura\", \"James\", \"Emma\"]\n",
    "    human_last_names = [\"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\", \"Rodriguez\", \"Martinez\"]\n",
    "    company_keywords = ['OF', 'SERVICES', 'COUNTY', 'DISTRIBUTOR', 'PRODUCTS', 'COUNTRY CLUB', 'PLLC', 'PRIVATE', \n",
    "                        'COMPANY', 'INC', 'RETIREMENT', 'DEVELOPMENT', 'HOA', 'AUTHORITY', 'CONF', 'CONFERENCE', \n",
    "                        'CONSTRUCTION', 'AFFORDABLE', 'HOUSING', 'MID COAST', 'ESTATE', 'REHABILITATION', 'GARDENS', \n",
    "                        'WELLNESS', 'LLC', 'STATE', 'LAND', 'MEMBERSHIP', 'COOPERATIVE', 'CORP', 'CORPORATION', \n",
    "                        'INDEPENDENT', 'CHURCH', 'ENTERPRISES', 'ACCOUNTING', 'INVESTMENTS', 'OWNERS', 'AIRPORT', \n",
    "                        'MAINTENANCE', 'ASSOCIATION', 'REALTY', 'FOUNDATION', 'CONSULTANTS', 'ASSOCIATES', \n",
    "                        'CORPORATE', 'DISTRICT', 'LTD', 'LIMITED', 'INCORPORATED', 'PROPERTIES', 'INVESTMENT', \n",
    "                        'NORTHEAST', 'PLUMBING', 'HEATING', 'TRUST']\n",
    "\n",
    "    data = []\n",
    "    for _ in range(num_records):\n",
    "        if random.random() < 0.5:\n",
    "            first_name = random.choice(human_first_names)\n",
    "            last_name = random.choice(human_last_names)\n",
    "            full_name = f\"{first_name} {last_name}\"\n",
    "            data.append({\"Full Name\": full_name, \"Name Type\": \"Human Name\"})\n",
    "        else:\n",
    "            company_name = f\"{random.choice(human_last_names)} {random.choice(company_keywords)}\"\n",
    "            data.append({\"Full Name\": company_name, \"Name Type\": \"Company Name\"})\n",
    "    return data\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_excel(\"Training Data Scrubbing Names 2.xlsx\")\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), analyzer='char')\n",
    "X = vectorizer.fit_transform(df['Full Name'])\n",
    "y = df['Name Type']\n",
    "\n",
    "# Shuffle and split the data into training and test sets\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X, y = X[indices], y.iloc[indices]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=2000, penalty='l2', C=0.35, solver='newton-cholesky')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy on Test Set: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Generate and test with synthetic data\n",
    "synthetic_data = generate_synthetic_data(2000)\n",
    "synthetic_X = vectorizer.transform([row['Full Name'] for row in synthetic_data])\n",
    "synthetic_y = [row['Name Type'] for row in synthetic_data]\n",
    "\n",
    "# Evaluate on synthetic data\n",
    "synthetic_pred = model.predict(synthetic_X)\n",
    "synthetic_accuracy = accuracy_score(synthetic_y, synthetic_pred)\n",
    "print(f\"Accuracy on Synthetic Data: {synthetic_accuracy * 100:.2f}%\")\n",
    "print(classification_report(synthetic_y, synthetic_pred))\n",
    "print(confusion_matrix(synthetic_y, synthetic_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "with open(\"name_classifier_logreg.pickle\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Synthetic Data: 93.48%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Company Name       0.97      0.90      0.93      5031\n",
      "  Human Name       0.91      0.97      0.94      4969\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.94      0.94      0.93     10000\n",
      "weighted avg       0.94      0.93      0.93     10000\n",
      "\n",
      "[[4534  497]\n",
      " [ 155 4814]]\n"
     ]
    }
   ],
   "source": [
    "# load the model \n",
    "model = pickle.load(open('name_classifier_logreg.pickle', 'rb'))\n",
    "\n",
    "\n",
    "# Generate and test with synthetic data\n",
    "synthetic_data = generate_synthetic_data(10000)\n",
    "synthetic_X = vectorizer.transform([row['Full Name'] for row in synthetic_data])\n",
    "synthetic_y = [row['Name Type'] for row in synthetic_data]\n",
    "# Evaluate on synthetic data\n",
    "synthetic_pred = model.predict(synthetic_X)\n",
    "synthetic_accuracy = accuracy_score(synthetic_y, synthetic_pred)\n",
    "print(f\"Accuracy on Synthetic Data: {synthetic_accuracy * 100:.2f}%\")\n",
    "print(classification_report(synthetic_y, synthetic_pred))\n",
    "print(confusion_matrix(synthetic_y, synthetic_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
